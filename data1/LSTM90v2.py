import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
import torch
from torch.utils.data import Dataset, DataLoader

# ========= é…ç½®å‚æ•° ========= #
input_hours = 90 * 24       # è¾“å…¥åºåˆ—é•¿åº¦ï¼ˆ90å¤©ï¼‰
output_hours = 90 * 24      # é¢„æµ‹åºåˆ—é•¿åº¦ï¼ˆ90å¤©ï¼‰
use_cols = [
    'Global_active_power','Global_reactive_power',
    'Global_intensity','Sub_metering_1',
    'Sub_metering_2','Sub_metering_3',
    'sub_metering_remainder'
]

# ========= è¯»å– & è¡¥å……å­—æ®µ ========= #
def load_hourly(path):
    df = pd.read_csv(path, parse_dates=['DateTime'])
    df.sort_values('DateTime', inplace=True)
    df.reset_index(drop=True, inplace=True)

    # è®¡ç®— sub_metering_remainder
    df["sub_metering_remainder"] = (
        df["Global_active_power"] * 1000 / 60
        - df["Sub_metering_1"]
        - df["Sub_metering_2"]
        - df["Sub_metering_3"]
    ).clip(lower=0)

    df = df[['DateTime'] + use_cols].copy()
    df.ffill(inplace=True)
    df.bfill(inplace=True)
    return df

train_df = load_hourly("train_hourly.csv")
test_df  = load_hourly("test_hourly.csv")  # âœ… ç›´æ¥åŠ è½½ï¼Œæ— éœ€ repeat

# åˆå¹¶æ•°æ®ï¼ˆç¡®ä¿æŒ‰æ—¶é—´æ‹¼æ¥ï¼‰
full_df = pd.concat([train_df, test_df], ignore_index=True)

# ========= æ ‡å‡†åŒ– ========= #
scaler = MinMaxScaler()
scaled = scaler.fit_transform(full_df[use_cols])
target = scaled[:, 0]  # ç›®æ ‡å€¼ï¼šGlobal_active_power

# ========= æ»‘åŠ¨çª—å£æ„é€ å‡½æ•° ========= #
def build_samples(data, target, input_len, output_len):
    X, y = [], []
    for i in range(input_len, len(data) - output_len):
        X.append(data[i - input_len:i])
        y.append(target[i:i + output_len])
    return np.array(X), np.array(y)

# ========= æ„å»ºæ ·æœ¬ ========= #
X_all, y_all = build_samples(scaled, target, input_hours, output_hours)

# ========= æ‹†åˆ† train / test ========= #
# é€šè¿‡æ—¶é—´æˆ³åˆ¤æ–­ test èµ·ç‚¹ï¼Œä¹Ÿå¯æ ¹æ® test_df çš„å¼€å§‹ç´¢å¼•æ¥åˆ‡åˆ†
split_index = len(train_df) - input_hours  # ä¿è¯ test çš„è¾“å…¥ä» train æœ«å°¾æ¥ä¸Š
X_train = X_all[:split_index]
y_train = y_all[:split_index]
X_test  = X_all[split_index:]
y_test  = y_all[split_index:]

print(f"X_train shape: {X_train.shape}")
print(f"y_train shape: {y_train.shape}")
print(f"X_test  shape: {X_test.shape}")
print(f"y_test  shape: {y_test.shape}")

import torch
import torch.nn as nn


class LSTMModel(nn.Module):
    def __init__(self, input_dim=7, hidden_size=128, num_layers=2, dropout=0.3, output_len=2160):
        super().__init__()
        self.bilstm = nn.LSTM(
            input_size=input_dim,
            hidden_size=hidden_size,
            num_layers=num_layers,
            dropout=dropout if num_layers > 1 else 0,
            batch_first=True,
            bidirectional=True
        )
        self.dropout = nn.Dropout(dropout)
        self.fc = nn.Linear(hidden_size * 2, output_len)  # åŒå‘ => 2 Ã— hidden_size

    def forward(self, x):
        # x shape: (batch_size, seq_len, input_dim)
        out, _ = self.bilstm(x)  # out: (batch_size, seq_len, hidden_size*2)
        out = self.dropout(out)
        out = out[:, -1, :]  # å–æœ€åæ—¶é—´æ­¥
        out = self.fc(out)  # è¾“å‡º (batch_size, 2160)
        return out


import torch
import torch.nn as nn
from torch.utils.data import random_split, DataLoader
from torch.utils.data import TensorDataset

train_ds = TensorDataset(
    torch.tensor(X_train, dtype=torch.float32),
    torch.tensor(y_train, dtype=torch.float32)
)

n_features = 7
patience = 10
no_improve_count = 0

model = LSTMModel(input_dim=n_features, output_len=2160)
# GPU è®¾å¤‡
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

# æ•°æ®é›†åˆ‡å‰²ï¼š80% è®­ç»ƒ, 20% éªŒè¯
total = len(train_ds)
train_size = int(total * 0.8)
val_size = total - train_size
train_subset, val_subset = random_split(train_ds, [train_size, val_size])

train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)
val_loader = DataLoader(val_subset, batch_size=64, shuffle=False)

# æŸå¤±å’Œä¼˜åŒ–å™¨
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

train_losses, val_losses = [], []
best_val = float('inf')
best_model = None
for epoch in range(1, 101):
    # â€”â€” è®­ç»ƒé˜¶æ®µ â€”â€” #
    model.train()
    total_train_loss = 0.0
    for xb, yb in train_loader:
        xb, yb = xb.to(device), yb.to(device)
        optimizer.zero_grad()
        pred = model(xb)
        loss = criterion(pred, yb)
        loss.backward()
        optimizer.step()
        total_train_loss += loss.item() * xb.size(0)
    avg_train = total_train_loss / len(train_subset)
    train_losses.append(avg_train)

    # â€”â€” éªŒè¯é˜¶æ®µ â€”â€” #
    model.eval()
    total_val_loss = 0.0
    with torch.no_grad():
        for xb, yb in val_loader:
            xb, yb = xb.to(device), yb.to(device)
            pred = model(xb)
            loss = criterion(pred, yb)
            total_val_loss += loss.item() * xb.size(0)
    avg_val = total_val_loss / len(val_subset)
    val_losses.append(avg_val)

    print(f"Epoch {epoch:02d}: Train Loss = {avg_train:.4f}, Val Loss = {avg_val:.4f}")
    if avg_val < best_val:
        best_val = avg_val
        best_model = model.state_dict()
        no_improve_count = 0
    else:
        no_improve_count += 1

    if no_improve_count >= patience:
        print(f"Early stopped at epoch {epoch}")
        break
# ğŸ” è®­ç»ƒ & éªŒè¯ Loss æ›²çº¿
import matplotlib.pyplot as plt
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False
plt.figure(figsize=(8, 4))
plt.plot(train_losses, label='Train MSE')
plt.plot(val_losses, label='Val   MSE')
plt.xlabel('Epoch')
plt.ylabel('Loss (MSE)')
plt.title('Training vs Validation Loss')
plt.legend()
plt.grid(True)
plt.savefig("Loss.png", dpi=300)
plt.show()


import numpy as np
import torch
import matplotlib.pyplot as plt
from sklearn.metrics import mean_absolute_error, mean_squared_error

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

# åŠ è½½æ¨¡å‹
model.load_state_dict(best_model)
model.eval()

# å‡†å¤‡æµ‹è¯•é›†
test_ds = torch.utils.data.TensorDataset(
    torch.tensor(X_test, dtype=torch.float32),
    torch.tensor(y_test, dtype=torch.float32)
)
test_loader = torch.utils.data.DataLoader(test_ds, batch_size=32, shuffle=False)

# é¢„æµ‹
preds, gts = [], []
with torch.no_grad():
    for xb, yb in test_loader:
        xb = xb.to(device)
        out = model(xb).cpu().numpy()  # shape: (batch_size, 2160)
        preds.append(out)
        gts.append(yb.numpy())

preds = np.concatenate(preds, axis=0)  # (N, 2160)
gts   = np.concatenate(gts,   axis=0)

# ========== åå½’ä¸€åŒ– ==========
zeros = np.zeros((preds.shape[0], preds.shape[1], 6))  # (N, 2160, 6)
preds_padded = np.concatenate([preds[..., np.newaxis], zeros], axis=-1)
gts_padded   = np.concatenate([gts[..., np.newaxis], zeros], axis=-1)

preds_real, gts_real = [], []
for i in range(preds.shape[0]):
    pred_inv = scaler.inverse_transform(preds_padded[i])[:, 0]
    gt_inv   = scaler.inverse_transform(gts_padded[i])[:, 0]
    preds_real.append(pred_inv)
    gts_real.append(gt_inv)

preds_real = np.array(preds_real)  # shape: (N, 2160)
gts_real   = np.array(gts_real)

# ========== èšåˆä¸ºæ¯å¤© ==========
# æ¯24å°æ—¶ä¸ºä¸€ç»„ -> reshape (N, 90, 24) -> axis=2 mean -> (N, 90)
preds_day = preds_real.reshape(preds_real.shape[0], 90, 24).mean(axis=2)
gts_day   = gts_real.reshape(gts_real.shape[0], 90, 24).mean(axis=2)

# ========== è¯„ä¼°æŒ‡æ ‡ï¼ˆå°æ—¶çº§ï¼‰==========
mae_hour  = mean_absolute_error(gts_real, preds_real)
rmse_hour = np.sqrt(mean_squared_error(gts_real, preds_real))
print(f"åå½’ä¸€åŒ–åï¼ˆå°æ—¶çº§ï¼‰ MAE: {mae_hour:.4f} kW")
print(f"åå½’ä¸€åŒ–åï¼ˆå°æ—¶çº§ï¼‰ RMSE: {rmse_hour:.4f} kW")

# ========== å¯è§†åŒ–ä¸€ä¸ªæ ·æœ¬ï¼ˆæŒ‰å¤©ï¼‰==========
plt.figure(figsize=(10, 5))
plt.plot(gts_day[0], label="çœŸå®å€¼", linewidth=1.2)
plt.plot(preds_day[0], label="é¢„æµ‹å€¼", linewidth=1.2)
plt.xlabel("æœªæ¥å¤©æ•°")
plt.ylabel("æ¯æ—¥å¹³å‡æ€»æœ‰åŠŸåŠŸç‡ï¼ˆkWï¼‰")
plt.title("æœªæ¥90å¤©é¢„æµ‹ vs çœŸå®å€¼ï¼ˆæ¯æ—¥èšåˆï¼‰")
plt.xticks(ticks=np.arange(0, 91, 5))  # æ¯5å¤©ä¸€ä¸ªåˆ»åº¦
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.savefig("prediction_vs_truth.png", dpi=300)
plt.show()
